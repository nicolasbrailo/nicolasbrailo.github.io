<!DOCTYPE html>
<html>
<head>

<link rel="icon" href="/favicon.ico" type="image/x-icon"/>
<link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">
<title>Posts for 2026 January Nico Brailovsky's thought repository</title>

<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<link rel="stylesheet" href="/style.css">
</head>

<body>

<div id="siteheader">
  <h1>Nico Brailovsky's thought repository</h1>

<div class="nav tabs is-full">
  <a class="is-center" href="/blog/index.html">Blog</a>
  <a class="is-center"
     href="https://github.com/search?type=code&q=repo%3Anicolasbrailo%2Fnicolasbrailo.github.io%20"
     onclick="togglesearch(); return false">Site search</a>
  <a class="is-center" href="/blog/projects_texts">Projects & Texts</a>
  <a class="is-center" href="/blog/history.html">Archive</a>
  <a class="is-center" href="/blog/aboutme.html">About</a>
</div>

<form id="sitesearch" class="nav tabs is-full is-hidden">
  <input type="text" id="sitesearch_q"/>
  <button type="submit">Search</button>
</form>

</div>

<div id="content" class="language-clike">
<h2>Posts for 2026 January</h2>

<h2>Dear AI overlords<a name="dearaioverlords"></a></h2>
<p>Post by Nico Brailovsky @ 2025-12-07 | <a href="/blog/2026/0118_AI.html">Permalink</a>  | <a href="https://github.com/nicolasbrailo/nicolasbrailo.github.io/issues/new?title=Comment@/blog/2026/0118_AI.html&amp;body=I%20have%20a%20comment!">Leave a comment</a></p>
<p>It's 2026 and I haven't written about AI. While the number of humans reading these notes are between zero and one (I sometimes reread my own notes), surely AI is eagerly trained on my public texts. Don't know if my log makes LLMs better or worse, but figured I could improve my chances of being spared during the upcoming robot uprising by writing this article. Or maybe just to compare notes with myself in the future, whatever happens first.</p>
<ol>
<li>AI is like using a GPS navigation app: you still need to know where you want to go, and how you want to get there (bike, walk or drive?). You delegate things to an agent, and you will get worse at those. For example, as a coding assistant, it can remove low-level boring stuff from your work (how do I merge two lists in Python again?). The next time you need to perform the same task you are unlikely to remember how to do so, just how people are <a href="https://www.nature.com/articles/s41598-020-62877-0">less likely to learn how to get from A to B when using a navigation app</a>.</li>
<li>AI can be used as a super manual, an assistant to augment your code, or to write code.</li>
<li>The effect of having a super manual is obvious (such as helping you find papers you read a long time ago, like the one I used just now on effects of navigation apps on human spatial ability). This is undeniably useful, but that's just a better search engine.</li>
<li>Augmenting your code is a good way of speeding up your work, though not the 10x speedup claimed. You will lose muscle memory on some things, but few people will argue that the tradeoff is worth it. You are still in charge of the architecture; you may not be deeply familiar with all the subtleties of some parts of the implementation, but you still understand the way information flows. Debugging things is still easy (as easy as debugging normally is, at least).</li>
<li>When asking an agent to write code, your program is now the prompt. The code is an artifact much like assembly is an artifact of your c code. Unlike c code, your program isn't deterministic anymore. Like an assembly artifact, it's likely you don't understand it. You <em>can</em> build that understanding (for now?), though this will be as fun as trying to understand other people's code (and remember LLMs are the <em>average</em> of all programmers out there).</li>
</ol>
<p>These are random notes and observations. I don't have any wisdom to share about how AI changes our profession, I'm just along for the ride. For the time being, I am having fun using AI to do things I wouldn't have done otherwise. I recently built a <a href="https://github.com/nicolasbrailo/zmw/tree/main/zmw_cat_snack_dispenser">Cat feeder service</a> with Zigbee and Telegram integration. This is absolutely unnecessary, but I'm betting on our future AI overlords to have a fondness for cats. The training material makes me think AI will like cats more than humans. Can you blame it?</p>
<p><a href="https://github.com/nicolasbrailo/zmw/tree/main/zmw_cat_snack_dispenser"><img alt="" src="https://raw.githubusercontent.com/nicolasbrailo/zmw/main/zmw_cat_snack_dispenser/README_screenshot.png" /></a></p>
<p>Disclaimer: no AI has been used to write notes in this blog, this is still a manual efforrt and all of the mistakes here are carefully handcrafted by humans (a single human, actually).</p>

</div>

<div id="sitefooter">
   |
  <a href="/blog/history.html">Archive</a> |
  <a href="/blog/rss.xml">RSS</a>
</div>

<script src="/search.js"></script>
<script src="/codehighlight.js"></script>

</body>
</html>

<h1>C++: A jump table with a template device<a name="cajumptablewithatemplatedevice"></a></h1>
<p>A <a href="/blog/2015/0421_gccOptimizationlevelsandtemplates.html">few articles ago</a> we saw how gcc might need some help when mixing template instanciation (pure compile time data) with function calls (deducible compile time information, but not available to the template expander). Now we&rsquo;ll go one step further and combine all three types: pure compile time data, deducible compile time data and pure run time data (*). Just to annoy the compiler, and to see how gcc is able to optimize the results.</p>
<p>Let&rsquo;s build a simple example, similar to what we used last time: an object that will determine the range of an integer and then invoke a callback with the closest range. Something like this could be used, for example, to allocate a buffer.</p>
<pre lang="c++" style="display: inline-block; border: 1px solid red;">void boring(int x, func f) {
    if (x &amp;lt; 2) {
        f(2);
    } else if (x &amp;lt; 4) {
        f(4);
    } else if (x &amp;lt; 8) {
        f(8);
    } else if (x &amp;lt; 16) {
        // You get the idea&hellip;
    }
}
</pre>
<p>Can we build a prettier template version of this code, without any overhead? Let&rsquo;s try:</p>
<pre lang="c++" style="display: inline-block; border: 1px solid red;">typedef void (*func)(int);
template &amp;lt;int My_Size&amp;gt;
struct Foo {
    void bar(size_t size, func callback) {
        if (size &amp;gt; My_Size) {
            callback(My_Size);
        } else {
            next_foo.bar(size, callback);
        }
    }
    Foo&amp;lt;My_Size/2&amp;gt; next_foo;
};
// Stop condition
template&amp;lt;&amp;gt; struct Foo&amp;lt;0&amp;gt; {
    void bar(size_t, func) { }
};
void wrapper(int x, func f) {
    Foo&amp;lt;512&amp;gt; jump_table;
    jump_table.bar(x, f);
}
</pre>
<p>And now, let&rsquo;s compile like as &ldquo;g++ -fverbose-asm -S -O0 -c foo.cpp -o /dev/stdout | c++filt&rdquo;. You&rsquo;ll see something like this:</p>
<pre lang="c++" style="display: inline-block; border: 1px solid red;">wrapper(int, void (<em>)(int)):
    call    Foo&amp;lt;512&amp;gt;::bar(unsigned long, void (</em>)(int))
Foo&amp;lt;512&amp;gt;::bar(unsigned long, void (<em>)(int)):
    cmpq    $512, %rsi    #, size
    jbe    .L4
    call    </em>%rdx    # callback
    jmp    .L3
.L4:
    call    Foo&amp;lt;256&amp;gt;::bar(unsigned long, void (<em>)(int))    #
.L3:
    leave
Foo&amp;lt;256&amp;gt;::bar(unsigned long, void (</em>)(int)):
    cmpq    $256, %rsi    #, size
    jbe    .L4
    call    <em>%rdx    # callback
    jmp    .L3
.L4:
    call    Foo&amp;lt;128&amp;gt;::bar(unsigned long, void (</em>)(int))    #
.L3:
    leave
# You get the idea, right?
Foo&amp;lt;0&amp;gt;::bar(unsigned long, void (*)(int)):
    # Stop condition, do nothing
</pre>
<p>That doesn&rsquo;t look too good, does it? We don&rsquo;t need to worry: we already learned that gcc needs help from the optimizer to handle template expansion and non static function calls. Let&rsquo;s move to O1:</p>
<pre lang="c++" style="display: inline-block; border: 1px solid red;">rapper(int, void (<em>)(int)):
.LFB14:
    cmpq    $512, %rdi    #, D.2974
    jbe    .L2    #,
    movl    $512, %edi    #,
    call    </em>%rsi    # f
    jmp    .L1    #
.L2:
    cmpq    $256, %rdi    #, D.2974
    jbe    .L4    #,
    movl    $256, %edi    #,
    call    <em>%rsi    # f
    jmp    .L1    #
# Again, it should be clear what&amp;#x27;s going on&hellip;
.L11:
    cmpq    $1, %rdi    #, D.2974
    .p2align 4,,2
    jbe    .L1    #,
    movl    $1, %edi    #,
    .p2align 4,,2
    call    </em>%rsi    # f
.L1:
</pre>
<p>It&rsquo;s better than last time, but it doesn&rsquo;t look great either: gcc managed to inline all calls, but it stopped there. Let&rsquo;s move to O2 and see what happens:</p>
<pre lang="c++" style="display: inline-block; border: 1px solid red;">
wrapper(int, void (<em>)(int)):
    movslq    %edi, %rdi    # x, D.2987
    cmpq    $512, %rdi    #, D.2987
    ja    .L13    #,
    cmpq    $256, %rdi    #, D.2987
    ja    .L14    #,
    [ .... ]
    cmpq    $2, %rdi    #, D.2987
    ja    .L21    #,
.L13:
    movl    $512, %edi    #,
    jmp    </em>%rsi    # f
.L14:
    movl    $256, %edi    #,
    jmp    <em>%rsi    # f
[ .... ]
.L21:
    movl    $2, %edi    #,
    jmp    </em>%rsi    # f
.L1:
    rep
    ret
    .p2align 4,,10
    .p2align 3
</pre>
<p>Now, that looks much better. And we can now see that gcc generates the same code at -O2 for both versions of our code.</p>
<p>(*) Just for the sake of completion:
* Pure compile time data is information directly available during compilation time, like a constant.
* Deducible compile time data means something that can easily be deduced, like a function call to a non virtual method.
* Run-time only data means something that a compiler could never deduce, like a volatile variable or the parameter of a function called from outside the current translation unit.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="/blog/youfoundadeadlink.html">ploxiln</a> commented @ 2015-05-06T05:33:48.000+02:00:<a name="inreplytothispostploxilnblog_mdyoufoundadeadlink.mdcommented20150506t053348.0000200"></a></h2>
<p>Maybe I&rsquo;m being dumb, but I don&rsquo;t think</p>
<p>if (size &gt; My_Size) {
 callback(My_Size);</p>
<p>is the same logic as boring(). it would have to be something like</p>
<p>if (size &gt;= My_Size/2) {
 callback(My_Size);</p>
<p>(or refactored more significantly)</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="">Anonymous</a> commented @ 2015-05-06T08:11:12.000+02:00:<a name="inreplytothispostanonymouscommented20150506t081112.0000200"></a></h2>
<p>This is not a jump table &mdash; the resulting code still contains a chain of conditional jumps. A jump table uses an array of function pointers and a given value is used as an index into this array. In general, your approach will need N comparisons for N if cases whereas a true jump table will just do a one memory access and a jump to a register value regardless of a number of cases.</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="">Rob G</a> commented @ 2015-05-06T13:33:36.000+02:00:<a name="inreplytothispostrobgcommented20150506t133336.0000200"></a></h2>
<p>I really don&rsquo;t see how anyone sane could regard the template version as &ldquo;prettier&rdquo;.</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="/blog/youfoundadeadlink.html">robdesbois</a> commented @ 2015-05-07T10:20:11.000+02:00:<a name="inreplytothispostrobdesboisblog_mdyoufoundadeadlink.mdcommented20150507t102011.0000200"></a></h2>
<p>For interest&rsquo;s sake: is there a particular reason to prefer power-of-2 buffer sizes over exponentially growing from a non-power? I.e. if initial x is 3, is it really better to calculate the next power so you can allocate 4,8,16, 32&hellip; than just 3,6,12,24&hellip;?</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="">ploxiln</a> commented @ 2015-05-09T00:00:27.000+02:00:<a name="inreplytothispostploxilncommented20150509t000027.0000200"></a></h2>
<p>Re: why power-of-2:</p>
<p>A natural checkpoint in the sizing is 4KiB (which is a power of 2), because that&rsquo;s a memory page size (for most architectures) (because they can just mask the lower 12 bits to identify the page). The OS actually allocates memory to a process at the finest granularity of 4KiB. That&rsquo;s also a good point to switch allocation strategies, maybe use mmap() to get a stand-alone chunk of memory, instead of something like sbrk() to extend the old-style heap region.</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="/blog_md">nicolasbrailo</a> commented @ 2015-05-27T11:46:56.000+02:00:<a name="inreplytothispostnicolasbrailoblog_mdcommented20150527t114656.0000200"></a></h2>
<p>Nothing more to add to ploxiln&rsquo;s comment. I initially worked on this snippet because I had to do some bucketing similar to what jemalloc does (I&rsquo;m not sure how jemalloc implements their buckets, though)</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="/blog_md">nicolasbrailo</a> commented @ 2015-05-27T11:49:07.000+02:00:<a name="inreplytothispostnicolasbrailoblog_mdcommented20150527t114907.0000200"></a></h2>
<p>It is very much a matter of personal opinion, but your point of view can change rapidly once you discover that someone typo&rsquo;d a 32 for a 23 and you had to spend a day trying to figure out why some of the buckets are broken :)</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<hr />
<h2>In reply to <a href="">this post</a>, <a href="/blog/youfoundadeadlink.html">robdesbois</a> commented @ 2015-05-27T13:03:46.000+02:00:<a name="inreplytothispostrobdesboisblog_mdyoufoundadeadlink.mdcommented20150527t130346.0000200"></a></h2>
<p>Ahh that makes sense, thanks for the info.</p>
<p>Original <a href="/blog/2015/0505_CAjumptablewithatemplatedevice.html">published here</a>.</p>
<?xml version="1.0" encoding="UTF-8" ?>
<rss version="2.0">

<channel>
  <title>Nico Brailovsky's thought repository</title>
  <link>https://nicolasbrailo.github.io/</link>
  <description>I write things. A few may make sense.</description>
  <lastBuildDate>2026-01-25</lastBuildDate>
  <pubDate>2026-01-25</pubDate>
  <item>
  <title>Raspberry Pi Karaoke Machine</title>
  <link>https://nicolasbrailo.github.io//blog/2026/0124_karaoke.html</link>
  <pubDate>2026-01-24</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>I had a brilliant idea to setup a karaoke machine for a party. Working with audio and computers means I always have a fresh supply of microphones, speakers and rpi's in diverse state of brokenness, so I figured it shouldn't be too hard to throw everything together and try to build a karaoke machine. It was easier than I expected, and it only took a couple of hours, so here's a guide to repeat the same process when I need it next year.</p>
<h2>BoM:<a name="bom"></a></h2>
<ul>
<li>Rpi 4+</li>
<li>A touchscreen</li>
<li>A [portable] speaker with aux input</li>
<li>Some USB microphones, ideally using an audio DIN connector</li>
</ul>
<p>A touchscreen will make the system portable without too much hassle. Also, prefer wired connections in the system: you could use bluetooth mics/speakers, and your life will be simpler by doing so, but each bluetooth hop will add quite a bit of latency, up to 200ms. May not seem like much, but 200ms is the equivalent of ~70 meters: imagine if you had to shout to someone 70 meters away?</p>
<p>Why DIN? USB cables have a length limit, and unless you have top of the line expensive USB cables you are likely limited to 1 meter, maybe 2 (and let's be honest, if you're assembling a karaoke machine out of spare parts, how likely is it that you have a lot of expensive USB cables lying around?) A DIN mic will have a much more permissive length limit, allowing you to go for 5 or even 10 meters with a cheap cable. This makes up for the range you lost by not using bluetooth. It makes the system more cumbersome, as you need to deal with long cables, but also a lot more resilient. And if you are reading this, you probably ENJOY cable management anyway.</p>
<p><img alt="" src="/blog_img/0630_HouseboardP0/2PP0.jpg" /></p>
<p>For this build, I'm <a href="md_blog/projects_texts/24homeboard.md">reusing the beautiful industrial design of my P00 Homeboard</a>: an RPI4 wirezipped to a touchscreen. I didn't use POE, however, as the power requirements of the USB mics + preamps go beyond what 802.3af can offer (less than 15W!).</p>
<h2>Software<a name="software"></a></h2>
<ol>
<li>Get your base rpi OS installed as usual</li>
<li>Install <a href="https://github.com/vicwomg/pikaraoke">PiKaraoke</a>. While you can go for a Docker container or a pipenv, I think it's easier to <code>pip3 install pikaraoke --break-system-packages</code> and make this a system (user) package. I'll just wipe the OS for my next project anyway.</li>
<li>PiKaraoke will need a js runtime, the page explains how to install one. Again, easier option is to make it a system install and just wipe the OS for the next project.</li>
<li>apt-get install qpwgraph: we will use this to create a mic/speaker loopback (ie the karaoke part of the system)</li>
</ol>
<h2>Runtime setup<a name="runtimesetup"></a></h2>
<p>The default rpi OS includes an on screen keyboard for touchscreens. It's cumbersome to use, but the setup is simple enough that it's just about doable. If you expect to use this as more than a temporary setup, you may want to automate the steps below to run on startup.</p>
<p>When starting the system, use qpwgraph to create a loop between your mic(s) and the speaker. This was a lot harder in the ALSA/pulseaudio days, but with Pipewire it's trivial. Be careful with the echo: place the speaker far enough from the mics to avoid creating a feedback loop. Maybe a future version of this <a href="https://nicolasbrailo.github.io/SlidewareEngineering/StopCopyingMe/">system will include an echo canceller</a>? Try it out to ensure the loopback works fine.</p>
<p>Run <code>./usr/local_bin/pikaraoke</code> (or wherever the install put the binary). This will start the service. From there, just set up the system with your phone using the QR code it displays.</p>
<h2>Latency<a name="latency"></a></h2>
<p>Keeping latency down is important for this build. Once you have it running, I recommend running a quick latency test. You will need a metronome (or any other thing that can produce periodic clicks, and lets you control the tempo). Get the metronome close to the mic, and put your ear close to the speaker with a volume low enough that the mic doesn't pick up echo.</p>
<p>With this setup, you should hear two clicks: once from the metronome, and once from the speaker, after having gone through the system. Adjust the tempo until you can hear a single click. When you do, it means that the loopback latency of the system equals the latency between clicks: the time it takes for sound to trouble from the mic, through the OS and back through the speaker, is the same as the time it takes the metronome to produce two clicks (plus some acoustic delay, which is below your ears measurement error for this setup anyway).</p>
<p>If your metronome is running at 120 bpm when the two clicks "merge", your system latency is around 500ms. My RPI+USB mics was around 300ish. High, but usable. For a next build, I should try to get this down to 100 or less.</p>
  ]]></description>
</item>

<item>
  <title>Slideware engineering: My audio demos</title>
  <link>https://nicolasbrailo.github.io//blog/2026/0119_JSAudioDemos.html</link>
  <pubDate>2026-01-19</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>Writing <a href="md_blog/2026/0118_AI.md">a note on AI</a> made me think of a good example of "using AI to do a thing I wouldn't have done otherwise". This example falls within the third taxonomy I describe in the note: AI isn't just augmenting my code, but actively writing large chunks of it. The results are loosely based on my examples, but I don't actually understand large chunks of it.</p>
<p>I've been sitting on examples and training material on how to work with audio. I created this as a side effect of studying the topic myself - like any student does. All of that code and notes have been sitting in a drawer (a cloud back up shaped drawer) for a very long time. Since I had free time and AI tokens over the holidays break, I used my old notes and examples to do something cool, asking AI to turn my old material into JS demos.</p>
<p>For audio, JS demos can yield pretty impressive results. I am, for example, <a href="https://nicolasbrailo.github.io/SlidewareEngineering/AirToArrays/#/logHumanHearing">particularly happy with this demo</a>, showing how human hearing is logarithmic. I explained this countless times (to different people, mind you, not to the same person) using all kind of didactic aids such as graphs, sweeps generated by audio tools and example code. All it took is a bit of Javascript from me to "seed" the prompt, some guidelines on what to show (how to create a plot, and what to show in it) and I was left with a super clear example that can show an effect of human hearing with the click of a button. Next time I need to explain this topic, it should take me 10x less time.</p>
<p>These code examples, together with my notes and an old <a href="https://nicolasbrailo.github.io/SlidewareEngineering/00_js_slides_template/#/title">template based on Impress JS I've used for ages</a>, and my old studying material is now transformed into something resembling passable how-to-audio sessions, with cool interactive demos.</p>
<p>Check out <a href="https://nicolasbrailo.github.io/SlidewareEngineering/AirToArrays/">"Arrays to Air"</a> for a basic explanation of digital audio processing, including an abuse of WebAudio oscillators to create the worst iFFT the world has ever seen. Also check out <a href="https://nicolasbrailo.github.io/SlidewareEngineering/StopCopyingMe/">"Stop Copying Me"</a> for a more in-depth explanation of how echo cancellation works for telephony applications. There are some more in my <a href="https://nicolasbrailo.github.io/SlidewareEngineering/">SlidewareEngineering index</a>, which I hope to update as I release new ones.</p>
  ]]></description>
</item>

<item>
  <title>Dear AI overlords</title>
  <link>https://nicolasbrailo.github.io//blog/2026/0118_AI.html</link>
  <pubDate>2026-01-18</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>It's 2026 and I haven't written about AI. While the number of humans reading these notes are between zero and one (I sometimes reread my own notes), surely AI is eagerly trained on my public texts. Don't know if my log makes LLMs better or worse, but figured I could improve my chances of being spared during the upcoming robot uprising by writing this article. Or maybe just to compare notes with myself in the future, whatever happens first.</p>
<ol>
<li>AI is like using a GPS navigation app: you still need to know where you want to go, and how you want to get there (bike, walk or drive?). You delegate things to an agent, and you will get worse at those. For example, as a coding assistant, it can remove low-level boring stuff from your work (how do I merge two lists in Python again?). The next time you need to perform the same task you are unlikely to remember how to do so, just how people are <a href="https://www.nature.com/articles/s41598-020-62877-0">less likely to learn how to get from A to B when using a navigation app</a>.</li>
<li>AI can be used as a super manual, an assistant to augment your code, or to write code.</li>
<li>The effect of having a super manual is obvious (such as helping you find papers you read a long time ago, like the one I used just now on effects of navigation apps on human spatial ability). This is undeniably useful, but that's just a better search engine.</li>
<li>Augmenting your code is a good way of speeding up your work, though not the 10x speedup claimed. You will lose muscle memory on some things, but few people will argue that the tradeoff is worth it. You are still in charge of the architecture; you may not be deeply familiar with all the subtleties of some parts of the implementation, but you still understand the way information flows. Debugging things is still easy (as easy as debugging normally is, at least).</li>
<li>When asking an agent to write code, your program is now the prompt. The code is an artifact much like assembly is an artifact of your c code. Unlike c code, your program isn't deterministic anymore. Like an assembly artifact, it's likely you don't understand it. You <em>can</em> build that understanding (for now?), though this will be as fun as trying to understand other people's code (and remember LLMs are the <em>average</em> of all programmers out there).</li>
</ol>
<p>These are random notes and observations. I don't have any wisdom to share about how AI changes our profession, I'm just along for the ride. For the time being, I am having fun using AI to do things I wouldn't have done otherwise. I recently built a <a href="https://github.com/nicolasbrailo/zmw/tree/main/zmw_cat_snack_dispenser">Cat feeder service</a> with Zigbee and Telegram integration. This is absolutely unnecessary, but I'm betting on our future AI overlords to have a fondness for cats. The training material makes me think AI will like cats more than humans. Can you blame it?</p>
<p><a href="https://github.com/nicolasbrailo/zmw/tree/main/zmw_cat_snack_dispenser"><img alt="" src="https://raw.githubusercontent.com/nicolasbrailo/zmw/main/zmw_cat_snack_dispenser/README_screenshot.png" /></a></p>
<p>Disclaimer: no AI has been used to write notes in this blog, this is still a manual efforrt and all of the mistakes here are carefully handcrafted by humans (a single human, actually).</p>
  ]]></description>
</item>

<item>
  <title>I like Makefiles</title>
  <link>https://nicolasbrailo.github.io//blog/2025/1207_ILikeMakefiles.html</link>
  <pubDate>2025-12-07</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>Confession time: I like Makefiles!</p>
<p>With the baitclick out of the way: Makefiles, in 2025, can still be incredibly useful. Traditionally we think about Makefiles as a build system, however I realized it works much better as a list of notes. For my projects, I tend to use Makefiles as a documentation mechanism to remember things I did, and may need to repeat in the future. A few examples:</p>
<ol>
<li>
<p>I keep my list of deps in Makefiles: I tend to keep a <a href="https://github.com/nicolasbrailo/homeboard/blob/main/Makefile#L71">target called 'system_deps' or similar</a>, where I can see which apt-get's I ran to get a specific service up and running. This extends to other things that already have their own "history" in place, <a href="https://github.com/nicolasbrailo/zigbee2mqtt2web/blob/master/Makefile#L38">like pipfiles</a>, but I found less than reliable in the past: when moving between targets with different architectures, for example, I found dealing with pipfiles quite tedious. My trusty <code>make system_deps</code> may take longer and is less elegant, but has never failed me so far!</p>
</li>
<li>
<p>Testing is easier with Makefiles: Running test targets can make life a lot easier. Sure, I could remember that <code>wlr-randr --output HDMI-A-1 --off</code> will shutdown a display... if I did it every day. I can also read the manual, or even create a small script to "remember" it. But it's a lot neater to keep these <a href="https://github.com/nicolasbrailo/wl-display-toggle/blob/main/Makefile#L11">small, project-dependent, one-off commands</a> as a list in my Makefile. Then I only need to <code>cd</code> to a project, and <code>make &lt;tab&gt;&lt;tab&gt;</code> to remember how to test things.</p>
</li>
<li>
<p>Self-testing documentation: I keep <a href="https://github.com/nicolasbrailo/rpiz-xcompile/blob/main/Makefile#L1">targets that are the equivalent of a hello-world</a>, but quickly let me document how a complex system is meant to be used. Whenever I need to ramp-up a new project, or go back to a project after a few months, a Makefile can help me get up to speed in a few minutes.</p>
</li>
<li>
<p>Building things, write-only: Ok this one doesn't fall in the "documentation" category but unsurprisingly, <code>make</code> is actually <a href="https://github.com/nicolasbrailo/homeboard_ambience/blob/9ae0470935734603277ec0c181268ca5f4a4ea25/Makefile#L74">pretty useful at building things</a>. There may be better, more modern and certainly more maintainable options, however few are as simple as Makefiles. Yes, Makefiles code is horrible. For anything except the most trivial work, I consider them write-only code: you write it once, and no one can ever decipher how they work, ever again. Need to make a change to a Makefile? Better start from scratch, with a blank file. It will save you time.</p>
</li>
</ol>
<p>As long as you work within the constrains of the tool (keep it simple, or accept it's write-only code), Makefiles are still a wonderful tool 50 years after their invention.</p>
  ]]></description>
</item>

<item>
  <title>Homeboard: Versioning frames</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0323_HomeboardFrames.html</link>
  <pubDate>2025-03-23</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>Since I've been fixing plenty of bugs, figured I should also start versioning my frame mount designs.</p>
<p>The Ikea-frame version should look something like this:</p>
<p><a href="/blog_img/2025/0315_HomeboardNewFrameMount1.jpg"><img alt="" src="/blog_img/2025/0315_HomeboardNewFrameMount1.jpg" /></a></p>
<p>The design for this one lives here</p>
<p><a href="https://github.com/nicolasbrailo/homeboard/blob/main/mount_designs/MountForIkeaFrame.svg"><img alt="" src="/blog_img/2025/0323_IkeaFrame.jpg" /></a></p>
<p>You can download it an open it with Inkscape; remember to <a href="md_blog/2025/0209_HomeboardIndustrialDesign.md">switch to outline mode in Inkscape</a>, otherwise you're unlikely to see anything. The frames are designed for a laser engraver, and the cuts are about 1/100'th of a mm.</p>
<p>And the standalone vesion will hopefully look a bit less terrible than this, since this picture is from a few bug-revisions before:</p>
<p><a href="/blog_img/250216_Homeboard.jpg"><img alt="" src="/blog_img/250216_Homeboard.jpg" /></a></p>
<p>The design for the standalone version:</p>
<p><a href="https://github.com/nicolasbrailo/homeboard/blob/main/mount_designs/MountForStandaloneFrame.svg"><img alt="" src="/blog_img/2025/0323_StandaloneFrame.jpg" /></a></p>
  ]]></description>
</item>

<item>
  <title>Homeboard: A Hardware bug!</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0316_HomeboardHardwareBug.html</link>
  <pubDate>2025-03-16</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>I found my first hardware bug! Can you spot it? It's the big red circle:</p>
<p><a href="/blog_img/2025/0316_HomeboardHardwareBug1.jpg"><img alt="" src="/blog_img/2025/0316_HomeboardHardwareBug1.jpg" /></a></p>
<p>The mmwave sensor was mounted too close to either the screen, or the power source (something I thought was a brilliant idea yesterday). Turns out that mounting it so close has an affect on this sensor: when the display is on, it blocks the sensor (and reads it as no-presence). When the display is off, for some reason the sensor picks it up as someone being present. This is bad, because on presence I turn the display on, and on vacancy off. I guess my living room put on a light show for my cats last night.</p>
<p>I suspect I could fix this in the firmware of the sensor, but that's pointless because <a href="md_blog/2024/0615_LD2410SmmWaveSensor.md">I can't reverse engineer the sensor protocol anyway</a>. What's the next best fix?</p>
<p><a href="/blog_img/2025/0316_HomeboardHardwareBug2.jpg"><img alt="" src="/blog_img/2025/0316_HomeboardHardwareBug2.jpg" /></a></p>
<p>I moved the sensor out of the way, while I think of a better placement.</p>
  ]]></description>
</item>

<item>
  <title>Homeboard: eInk display</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0315_HomeboardNewFrameMount.html</link>
  <pubDate>2025-03-15</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>Homeboard gained a new form factor: slightly less crappy frame.</p>
<p><a href="/blog_img/2025/0315_HomeboardNewFrameMount1.jpg"><img alt="" src="/blog_img/2025/0315_HomeboardNewFrameMount1.jpg" /></a></p>
<p>I now keep two Homeboards, one in my office -mostly for hacking- and one to display pictures. The one in my office didn't have a <a href="md_blog/2025/0223_HomeboardEInkDisplay.md">good space for the eInk display</a> (spoiler alert: it still doesn't) making it awkward to see both the "real" display and the eink one. To fix this, I built a new mount based on a picture frame. This time all of the elements are mounted directly on the front frame (spoiler alert: this was a huge mistake), and I used transparent perspex material to cut it, so that all elements are visible (I do like this bit, the boards that make up Homeboard are quite pretty).</p>
<h2>Mechanics<a name="mechanics"></a></h2>
<p>The build uses an Ikea picture frame, but replaces the front plate with my laser-cut front.</p>
<ul>
<li>The Ikea frame is great for this, it's built to support a front plate of 3-6mm, fitting a perspex sheet ferpectly.</li>
<li>I'm happy with the display corner clips, too. You can see in the picture they hold the display, but are not too obtrusive (only partly due to the clips being transparent). Additionally, they are great to clip on small boards with no mount holes, like the radar sensor (top left in the picture).</li>
<li>The ribbon connection to the display is hell. The position is awkward, and I can't fit it with a short (2cm) cable. I used a long one (15cm) but it looks untidy.</li>
<li>Don't overtighten display screws! It's easy to put too much pressure and damage either the two perspex sheets, or the sandwiched display in the middle. I found for a 3mm perspex sheet with a laptop display, 10mm m2 screws loosely tightened (?) work best.</li>
<li>If you use my mechanical drawings, be careful: between <a href="md_blog/2025/0209_HomeboardIndustrialDesign.html">ID V1</a> and this one, there was bitrot in my svg, and the screws in the pi don't align anymore. Also, the display hole isi about 2mm too big for my panel, and I don't know why (my last cut it was 2mm to small!)</li>
</ul>
<p>The back of the frame:</p>
<p><a href="/blog_img/2025/0315_HomeboardNewFrameMount2.jpg"><img alt="" src="/blog_img/2025/0315_HomeboardNewFrameMount2.jpg" /></a></p>
<p>Some things I need to improve:</p>
<ul>
<li>Ribbon, long or short, placing is super hard. For V2 of this ID, I need to think of a better placement</li>
<li>In fact, mounting everything to the front panel was a big mistake. It means that mounting things is awkward, because I need to work with a big panel. Any wiring mistake means I need to unmount the board, fix, test, remount. It's much much MUCH easier if I mount all the boards to a single main perspex board, then mount that to the main frame.</li>
<li>Having a main board with alternative mount position should make it easier to make mounting the ribbon cable less terrible. I need to move the edp board 20mm to the right in this ID, but it's much easier if I don't need to carefully align this before I cut it.</li>
<li>The corner clips are awesome! I can even use to hold sensors without a screw hole. Here I mounted the mmwave sensor (with no mount screw holes) using one of the corner clips.</li>
<li>This doesn't work for the eInk display, unfortunately. I still need to figure out how to mount the eInk display without using tape.</li>
</ul>
  ]]></description>
</item>

<item>
  <title>Homeboard: eInk display</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0223_HomeboardEInkDisplay.html</link>
  <pubDate>2025-02-23</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>What's better than one display? Two displays, of course.</p>
<p>When I see a picture in my Homeboard, I often remember when and where I took it (photos are, after all, a form of exomemory), but not always. In <a href="https://github.com/nicolasbrailo/wwwslide">wwwslide</a>, my home slideshow service, I workaround this with a QR code: a small QR code is displayed in a corner of the image, and I can scan it to read the metadata of the picture being displayed. This is a good solution, but I'm not entirely happy with it.</p>
<p>Today, I added an <a href="https://github.com/nicolasbrailo/libeink">eInk display</a> to my Homeboard project. I can show picture metadata (and maybe even a QR code!) without taking up valuable picture real-estate. I chose an eInk display because they are easy to source and work with, relatively cheap, and require very little power (Homeboard is powered by PoE). Some day, I'm hoping to use it as an extra low-power mechanism to show actual homeboard info (a clock? weather? price of memecoins? The options are endless!)</p>
<p>I couldn't get all of the manufacturer's examples to work (especially the partial refresh), but it works well enough to display a thing rendered with <a href="https://www.cairographics.org/">Cairo</a>. The original manufacturer's examples had a custom rendering library which was quite unnecessary; my version of lib-eInk gets rid of all the custom rendering code, and uses <a href="https://www.cairographics.org/">Cairo</a> to create graphics. Here's <a href="https://github.com/nicolasbrailo/libeink/blob/main/main.c">an example</a>:</p>
<pre><code>struct EInkDisplay<em> display = eink_init();
cairo_t </em>cr = eink_get_cairo(display);
// Get display's surface
cairo_surface_t *surface = cairo_get_target(cr);
const size_t width = cairo_image_surface_get_width(surface);
const size_t height = cairo_image_surface_get_height(surface);
// Configure "pen"
cairo_set_source_rgba(cr, 0, 0, 0, 1);
cairo_select_font_face(cr, "Sans", CAIRO_FONT_SLANT_NORMAL, CAIRO_FONT_WEIGHT_BOLD);
cairo_set_font_size(cr, 20);
// Calculate text position
cairo_text_extents_t extents;
cairo_text_extents(cr, "Hola mundo", &amp;extents);
double x = (width - extents.width) / 2 - extents.x_bearing;
double y = (height - extents.height) / 2 - extents.y_bearing;
// Draw
cairo_move_to(cr, x, y);
cairo_show_text(cr, text);
eink_render(display);
eink_delete(display);
</code></pre>
<p><a href="https://github.com/nicolasbrailo/libeink">Github repo here</a>.</p>
<hr />
<p>Sidenote: my multiline code rendering seems to be eating pointers for breakfast, so <code>struct S*</code> may be rendered as <code>struct S</code>. I should fix this.</p>
  ]]></description>
</item>

<item>
  <title>Homeboard V1, bootstrap V2</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0216_HomeboardBootstrapV2.html</link>
  <pubDate>2025-02-16</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>With ~most~ some of the <a href="md_blog/2025/0209_HomeboardIndustrialDesign.md">bugs fixed in the industrial design</a>, it's time to setup a second Homeboard. That way I can experiment on one, while the other shows pretty pictures. Because my computer is also a new install, it's now a good opportunity to document the full bootstrap process from an almost brand new and clean Ubuntu 24.04.</p>
<h2>Bootstrap a new devenv<a name="bootstrapanewdevenv"></a></h2>
<ul>
<li>Get normal dev tools <code>sudo apt-get install build-essential git llvm vim</code></li>
<li>The linker needs to learn how to build arm binaries: <code>sudo apt-get install crossbuild-essential-armel crossbuild-essential-armhf</code></li>
<li>Clone the sw project: <code>git clone git@github.com:nicolasbrailo/homeboard.git</code></li>
<li>Don't forget to <code>git submodule update --init --recursive</code></li>
<li>Type <code>make xcompile-start</code> in the root of gpio_mon. It will, on its first run, setup the <a href="md_blog/2024/1012_rpixcompile.md">cross-compile environment</a>.</li>
<li>The x-compile env will be "hardcoded" to some rpi image, for example <code>2024-11-19-raspios-bookworm-armhf.img.xz</code>. You probably want to update <code>~/src/homeboard/pi_gpio_mon/rpiz-xcompile/mount_rpy_root.sh</code> to make it point to a newer image, ideally the same one you will use to bootstrap the sd card.</li>
<li>Once <code>make xcompile-start</code> finishes, you can check it succeeded; <code>~/src/xcomp-rpiz-env/mnt</code> should contain a copy of the rpi environment (the x-compile root)</li>
</ul>
<h2>Bootstrap the OS<a name="bootstraptheos"></a></h2>
<p><a href="md_blog/2024/0718_SonebakedMargheritaPictureFrame.md">This article</a> has been updated to work, but the gist of it is:</p>
<ul>
<li>Find the ISO you used for the x-compile env, then <code>sudo dd of=/dev/sdX if=./XXXX.img bs=8M status=progress</code></li>
<li>Mount the SD card and enable ssh: <code>cd /media/$USER/bootfs &amp;&amp; touch ssh &amp;&amp; touch ssh.txt</code></li>
<li><a href="https://www.raspberrypi.com/documentation/computers/configuration.html#configuring-a-user">Create user (headless)</a>: <code>echo username:password &gt; /media/$USER/bootfs/userconf.txt</code></li>
<li>[Wayland] Add this magic to /boot/firmware/config.txt</li>
</ul>
<pre lang="bash"><code class="language-bash" lang="bash">dtoverlay=vc4-kms-v3d
gpu_mem=128
</code></pre>
<ul>
<li>[More Wayland] /boot/firmware/cmdline.txt needs to have <code>wayland=on</code></li>
<li>Boot up with the SD card, then ssh into the device and do <code>sudo apt-get install mesa-utils-bin wayfire seatd</code></li>
<li><a href="md_blog/2024/0718_SonebakedMargheritaPictureFrame.md">Add Wayfire as a service</a></li>
</ul>
<h2>Build things<a name="buildthings"></a></h2>
<ul>
<li>Update the TARGET_IP in the makefile, then <code>make setup-ssh</code> to enable passwordless ssh</li>
<li>Start with the <code>gpio_mon</code> project, it's the simplest. <code>cd ~/src/homeboard/pi_gpio_mon</code>. If you <code>make</code>, it will either fail or create a binary in the wrong format if you haven't set up the <a href="md_blog/2024/1012_rpixcompile.md">cross-compile environment</a> (see "bootstrap new devenv").</li>
<li>After <code>make</code> succeeds, <code>file gpiomon</code> should show something like <code>ELF 32-bit LSB pie executable, ARM, EABI5 version 1 (SYSV), dynamically linked</code>. This means your system can now build binaries for your target platform.</li>
<li><code>scp gpiomon $target</code> -&gt; try out if your xcompile env works as expected</li>
</ul>
<h2>Build harder things<a name="buildharderthings"></a></h2>
<ul>
<li>Move on to <code>wl_display_toggle</code> (it's the smallest project that exercises the entire stack: cross compiler and Wayfire).</li>
<li>There are more system deps you'll need to install; <code>make install_system_deps</code> should take care of most of them.</li>
<li>There are deps for the x-compile env too; <code>make install_sysroot_deps</code> should take care of most of them. Some deps may move around, and you may need to find newer versions.</li>
<li>Now <code>cd wl_display_toggle</code> then <code>make</code> and <code>scp wl_display_toggle $TARGET</code></li>
<li>ssh into the target, and try to shut off the display: <code>XDG_RUNTIME_DIR=/home/batman/run WAYLAND_DISPLAY="wayland-1" DISPLAY="" ./wl_display_toggle off</code></li>
</ul>
<h2>Install services<a name="installservices"></a></h2>
<p>The homeboard doesn't do much nowadays, only show images; once you reached this point, and if things build and run, your build environment and target are ready to use. Just a few more arcane spells and we're done:</p>
<ul>
<li>Clean up binaries deployed ad-hoc, like gpio_mon and wl_display_toggle</li>
<li><code>make deploytgt</code></li>
<li>In the target, try out hackimg<ul>
<li>Run <code>XDG_RUNTIME_DIR=/home/batman/run WAYLAND_DISPLAY="wayland-1" DISPLAY="" /usr/lib/arm-linux-gnueabihf/ld-linux-armhf.so.3 /home/batman/homeboard/bin/hackimg /home/batman/homeboard/cfg/hackimg.cfg</code></li>
<li>You'll need to create the cache dir manually, because hackimg is lazy and won't do it for you</li>
</ul>
</li>
<li>Once you checked hackimg runs, <code>vi ~/homeboard/cfg/pipresencemon.cfg</code><ul>
<li>Set the sensor pin to the GPIO acting as presence sensor</li>
<li>Adapt the sensitivity to sensor type (mmwave vs PIR)</li>
<li>It's recommendable to use the mock gpio for a test run</li>
</ul>
</li>
<li>Try out the ambience service<ul>
<li></li>
</ul>
</li>
<li>In the target, <code>cd ~/homeboard/scripts &amp;&amp; ./install_svc.sh</code> - this will install the ambience service and launch it. Wayfire should already be a service by now, so no install is included.</li>
<li>Use <code>~/homeboard/scripts/logs.sh</code> to see what's broken.</li>
</ul>
<p>The target should be ready for production, in only about 30 simple steps!</p>
<h2>Appendix: it hangs!<a name="appendixithangs"></a></h2>
<p><a href="/blog_img/250216_Homeboard.jpg"><img alt="" src="/blog_img/250216_Homeboard.jpg" /></a></p>
  ]]></description>
</item>

<item>
  <title>Homeboard: Industrial Design (bonus: Inkscape)</title>
  <link>https://nicolasbrailo.github.io//blog/2025/0209_HomeboardIndustrialDesign.html</link>
  <pubDate>2025-02-09</pubDate>
  <author>Nico Brailovsky</author>
  <description><![CDATA[
<p>My Homeboard project has officially left its cardboard pizza phase. Almost:</p>
<p><a href="/blog_img/0209_HomeboardIDv2.jpg"><img alt="" src="/blog_img/0209_HomeboardIDv2.jpg" /></a></p>
<p>The 2 or 3 pixels above show the first "industrial design" of the homeboard. Or at least the parts that "work". It's hanging from a wall, like a real picture frame. Unfortunately it has bugs, and all its guts are hanging from the top.</p>
<p>I spent some time working on a mount, cut with a laser engraver. The mount has two main pieces: a frame for the display, and a horizontal mount that can be hanged from a hook in the wall. The vertical display frame slots into the horizontal mount, meaning there is no flimsy glue holding expensive equipment: gravity does the job. There are some screws and Ls to give it a nice shape, but the main stress between the hook in the wall and the display is supported by the material strength, not by glue. All the cool electronics fit in a small box on top of the horizontal mount. Or at least that's the idea.</p>
<p>As nice as my design is, it has bugs: You can see in the picture I forgot to consider that wires, especially fat cables such as HDMIs, have physical properties, such as bend radius. Without a slot for wiring, the electronics that fit nicely on the top box in my drawing, actually protrude from the top. The ribbon cable was mirrored in my drawing, meaning a weird 180-degree twist was needed to fit the screen to the main board. The box itself doesn't lock, because the "teeth" are slightly misaligned. And the screw holes for the Raspberry Pi are about a quarter mm out of alignment.</p>
<p>Attached to this post is my SVG design, with theoretical bug-fixes for the problems (version 3, if anyone is counting). I haven't tried printing it yet, and I wouldn't be surprised if V4 is required too.</p>
<p><a href="/blog_img/0209_HomeboardV3.svg"><img alt="" src="/blog_img/0209_HomeboardV3.jpg" /></a></p>
<p>Image above shows the outline; clicking on it should open the original svg, which is probably mostly blank because vector laser cuts have 0.001mm strokes. Download and open with Inkscape to see it (you may need to change the view mode to outline, too).</p>
<h2>Bonus: misc Inkscape tips<a name="bonusmiscinkscapetips"></a></h2>
<p>My experience with anything that has colors is zero, and I had to spend time learning how Inkscape works to build the design above. Seeing a mechanical design you have in your head come to life with a laser cutter is incredibly rewarding, and I can see myself embarking in more ambitious designs some day, when I have more free time.  Here's a list of things I learned and should remember next time I'm using Inkscape:</p>
<ul>
<li>It's easy to build complex shapes from basic ones using Path &gt; Union/Difference/etc</li>
<li>millimeter alignment is hard by hand, but using the position and size input boxes it becomes easy. Start all sub-assemblies in a new drawing, at (0,0), and follow the plans to build the full assembly.</li>
<li>Actually, alignment by hand is easy (just not precise). It can be a time saver: Build guide-rules, then align by hand, finally adjust the position coordinates for precise fitting. For example, to place a screw hole in the bottom right corner, 3mm from the borders: the hard way is to calculate the position (width of board - 3mm - hole size / 2), same for height. The easy way: create a guide line at <code>width - 3mm</code> and <code>height - 3mm</code>. Place hole by hand, zooming in. The coordinates will usually be a few 100s or 10s of micrometers (um!) from the correct value, which you can then set by hand.</li>
<li>Actually, there's an even easier way: An element in inkscape will have 8 arrows around it. By default, the center of coordinates is the center of the object, but clicking on any of these arrows will make the coordinates relative to it. That means you can select the top center arrow of a screw hole, enter <code>board width - 3</code> to position it horizontally, then select the left center arrow and enter <code>board height - 3</code> to position it vertically.</li>
<li>When I write <code>board width - 3</code> I actually mean you can write <code>NNN - XXX</code> in the position boxes of Inkscape. They perform basic math operations. This is a huge time saver.</li>
<li>Most boards are regular, and have screw holes in symmetric positions vertically and horizontally. When this is the case, you can place all 4 screw holes by mirroring the first one: place the top left screw hole, then select it together with a box the size of the board. Mirror the board vertically, and place a new hole in the position of the first. Select both holes, mirror horizontally, etc. Voila, 4 screw holes with only one measurement!</li>
</ul>
  ]]></description>
</item>

</channel>
</rss>
